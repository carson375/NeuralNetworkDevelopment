{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is the Neural Network implementation for the project\n",
    "\n",
    "#From the project .pdf: \n",
    "#2.2 Neural networks\n",
    "#•Apply a multilayer perceptron to this classification task.\n",
    "#–What is a good choice of # layers?\n",
    "#–What is a good choice of # hidden nodes in each layer?\n",
    "#–What is a good choice of hidden activation functions?\n",
    "#–What are good choices of learning rate and/or learning-rate schedule?\n",
    "#–Do batch-norm and/or dropout help?\n",
    "#•Apply a convolutional deep network to this classification task.\n",
    "#–Similar questions as the multilayer perceptron, plus. . .\n",
    "#–What is a good choice of # channels in each layer?\n",
    "#–What is a good choice of kernel size?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is for all imports for this implementation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch import tensor, cat\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn import datasets, linear_model, preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "Xtr_loadpath = 'Xtr.csv'\n",
    "Xts_loadpath = 'Xts.csv'\n",
    "ytr_loadpath = 'ytr.csv'\n",
    "\n",
    "Xtr = np.loadtxt(Xtr_loadpath, delimiter=\",\")\n",
    "Xts = np.loadtxt(Xts_loadpath, delimiter=\",\")\n",
    "ytr = np.loadtxt(ytr_loadpath, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the training data\n",
    "# Note: It appears preprocessing.scale() does not work\n",
    "#Xtr_standardized = Xtr/495.561*2 - 1\n",
    "#Xts_standardized = Xts/450.402*2 - 1\n",
    "#ytr_standardized= ytr\n",
    "\n",
    "standard = preprocessing.RobustScaler()\n",
    "\n",
    "Xtr_standardized = standard.fit_transform(Xtr)\n",
    "Xts_standardized = standard.fit_transform(Xts)\n",
    "ytr_standardized= ytr\n",
    "\n",
    "# save the standardized training data\n",
    "Xtr_savepath = 'Xtr_sklearn.csv'\n",
    "Xts_savepath = 'Xts_sklearn.csv'\n",
    "ytr_savepath = 'ytr_sklearn.csv'\n",
    "yts_hat_savepath = 'yts_hat_neural.csv'\n",
    "\n",
    "np.savetxt(Xtr_savepath, Xtr_standardized, delimiter=\",\")\n",
    "np.savetxt(Xts_savepath, Xts_standardized, delimiter=\",\")\n",
    "np.savetxt(ytr_savepath, ytr_standardized, delimiter=\",\")\n",
    "\n",
    "#Not sure if we need this\n",
    "#nfold = 10\n",
    "#kf = KFold(n_splits=nfold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADERS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(Xtr_standardized, ytr_standardized,test_size=0.2,shuffle=True)\n",
    "\n",
    "# Convert the arrays to PyTorch tensors\n",
    "Xtr_torch = torch.Tensor(Xtr)\n",
    "ytr_torch = torch.Tensor(ytr)\n",
    "Xts_torch = torch.Tensor(Xts)\n",
    "yts_torch = torch.Tensor(yts)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# Create a training Dataset\n",
    "train_ds = torch.utils.data.TensorDataset(Xtr_torch, ytr_torch)\n",
    "# Creates a training DataLoader from this Dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "# Create a testing Dataset\n",
    "test_ds = torch.utils.data.TensorDataset(Xts_torch, yts_torch)\n",
    "# Creates a testing DataLoader from this Dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Creation\n",
    "import torch.nn as nn\n",
    "\n",
    "nin = Xtr_standardized.shape[1] # dimension of input data\n",
    "\n",
    "nh = 4 # number of hidden units\n",
    "nout = 1 # number of outputs = 10 since there are 10 classes (I think this is 8 now)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,nin,nh,nout):\n",
    "        super(Net,self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.20)\n",
    "\n",
    "        self.input = nn.Linear(nin,16)\n",
    "        self.Hidden13 = nn.Linear(16,32)\n",
    "        self.Hidden14 = nn.Linear(32,64)\n",
    "        self.Hidden1 = nn.Linear(64,128)\n",
    "        self.Hidden2 = nn.Linear(128, 256)\n",
    "        self.Hidden3 = nn.Linear(256, 512)\n",
    "        self.Hidden17 = nn.Linear(512,512)\n",
    "        self.Hidden4 = nn.Linear(512, 1024)\n",
    "        self.Hidden5 = nn.Linear(1024, 2048)\n",
    "        self.Hidden11 = nn.Linear(2048, 4096)\n",
    "        self.Hidden12 = nn.Linear(4096, 2048)\n",
    "        self.Hidden6 = nn.Linear(2048, 1024)\n",
    "        self.Hidden7 = nn.Linear(1024, 512)\n",
    "        self.Hidden8 = nn.Linear(512, 256)\n",
    "        self.Hidden9 = nn.Linear(256, 128)\n",
    "        self.Hidden10 = nn.Linear(128, 64)\n",
    "        self.Hidden15 = nn.Linear(64,32)\n",
    "        self.Hidden16 = nn.Linear(32,16)\n",
    "        self.output = nn.Linear(16,nout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = (self.input(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = (self.Hidden13(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = (self.Hidden14(x))\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = (self.Hidden1(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = (self.Hidden2(x))\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = (self.Hidden3(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x= (self.Hidden8(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x= (self.Hidden9(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x= (self.Hidden10(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = (self.Hidden15(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = (self.Hidden16(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Net(nin=nin, nh=nh, nout=nout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Deep Network\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "nin = Xtr_standardized.shape[1] # dimension of input data\n",
    "\n",
    "nh = 4 # number of hidden units\n",
    "nout = 1 # number of outputs = 10 since there are 10 classes (I think this is 8 now)\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,nin,nh,nout):\n",
    "        super(Net,self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "        self.Conv1 = nn.Conv1d(nin, 16, 3, padding=1)\n",
    "        #self.Conv12 = nn.Conv1d(64, 64, 5, padding=2)\n",
    "        self.Conv2 = nn.Conv1d(16, 8, 3, padding=1)\n",
    "        #self.Conv22 = nn.Conv1d(32, 32, 5, padding=2)\n",
    "        self.Conv3 = nn.Conv1d(8, 4, 3, padding=1)\n",
    "        #self.Conv32 = nn.Conv1d(16, 16, 3, padding=1)\n",
    "        self.Conv4 = nn.Conv1d(4, nin, 3, padding=1)\n",
    "        #self.Conv42 = nn.Conv1d(8, 8, 3, padding=1)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm1d(128)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(2048)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        self.bn6 = nn.BatchNorm1d(4096)\n",
    "\n",
    "        self.input = nn.Linear(nin,64)\n",
    "        self.Hidden1 = nn.Linear(64,128)\n",
    "        self.Hidden2 = nn.Linear(128, 256)\n",
    "        self.Hidden3 = nn.Linear(256, 512)\n",
    "        self.Hidden4 = nn.Linear(512, 1024)\n",
    "        self.Hidden5 = nn.Linear(1024, 2048)\n",
    "        self.Hidden11 = nn.Linear(2048, 4096)\n",
    "        self.Hidden12 = nn.Linear(4096, 2048)\n",
    "        self.Hidden6 = nn.Linear(2048, 1024)\n",
    "        self.Hidden7 = nn.Linear(1024, 512)\n",
    "        self.Hidden8 = nn.Linear(512, 256)\n",
    "        self.Hidden9 = nn.Linear(256, 128)\n",
    "        self.Hidden10 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64,nout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "\n",
    "        x = x.permute(1,0)\n",
    "        x = self.relu(self.Conv1(x))\n",
    "        #x = self.relu(self.Conv12(x))\n",
    "        x = self.relu((self.Conv2(x)))\n",
    "        #x = self.relu((self.Conv22(x)))\n",
    "        x = self.relu((self.Conv3(x)))\n",
    "        #x = self.relu((self.Conv32(x)))\n",
    "        x = self.relu((self.Conv4(x)))\n",
    "        #x = self.relu((self.Conv42(x)))\n",
    "        x = x.permute(1, 0)\n",
    "\n",
    "        x = self.relu(self.input(x))\n",
    "\n",
    "        x = self.relu(self.Hidden1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn0(x)\n",
    "\n",
    "        x = self.relu(self.Hidden2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.relu(self.Hidden3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        #x= self.relu(self.Hidden4(x))\n",
    "        #x = self.dropout(x)\n",
    "       #x= self.bn3(x)\n",
    "        \n",
    "        # x= self.relu(self.Hidden5(x))\n",
    "        # x= self.bn4(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        # x = self.relu(self.Hidden11(x))\n",
    "        # x = self.bn6(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        # x = self.relu(self.Hidden12(x))\n",
    "        # x = self.bn4(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        # x= self.relu(self.Hidden6(x))\n",
    "        # x= self.bn3(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        #x= self.relu(self.Hidden7(x))\n",
    "       # x= self.bn2(x)\n",
    "       # x = self.dropout(x)\n",
    "\n",
    "        x= self.relu(self.Hidden8(x))\n",
    "        x= self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x= self.relu(self.Hidden9(x))\n",
    "        x= self.bn0(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x= self.relu(self.Hidden10(x))\n",
    "        x= self.bn5(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "#model = ConvNet(nin=nin, nh=nh, nout=nout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1   Train Accuracy: 85.900%   Test Accuracy: 86.100%\n",
      "Epoch:  2   Train Accuracy: 86.562%   Test Accuracy: 85.850%\n",
      "Epoch:  3   Train Accuracy: 86.475%   Test Accuracy: 86.400%\n",
      "Epoch:  4   Train Accuracy: 86.188%   Test Accuracy: 86.500%\n",
      "Epoch:  5   Train Accuracy: 86.487%   Test Accuracy: 86.200%\n",
      "Epoch:  6   Train Accuracy: 86.675%   Test Accuracy: 86.100%\n",
      "Epoch:  7   Train Accuracy: 86.625%   Test Accuracy: 85.900%\n",
      "Epoch:  8   Train Accuracy: 86.900%   Test Accuracy: 86.600%\n",
      "Epoch:  9   Train Accuracy: 87.087%   Test Accuracy: 86.200%\n",
      "Epoch: 10   Train Accuracy: 87.237%   Test Accuracy: 85.250%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get training and test accuracy\n",
    "import torch.optim as optim\n",
    "lr = 1e-3\n",
    "# TODO\n",
    "criterion = nn.BCELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 10\n",
    "lrate = lr\n",
    "\n",
    "basic_tr_accuracy = []\n",
    "basic_ts_accuracy = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    correct = 0 # initialize error counter\n",
    "    total = 0 # initialize total counter\n",
    "    model.train() # put model in training mode\n",
    "    # iterate over training set\n",
    "    for train_iter, data in enumerate(train_loader):\n",
    "        x_batch,y_batch = data\n",
    "        y_batch = y_batch.to(torch.float32)\n",
    "        out = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(out.reshape(-1),y_batch)\n",
    "        # Zero gradients\n",
    "        opt.zero_grad()\n",
    "        # Compute gradients using back propagation\n",
    "        loss.backward()\n",
    "        # Take an optimization 'step'\n",
    "        opt.step()\n",
    "        \n",
    "        # Compute Accuracy\n",
    "        guess = out.round().reshape(-1)\n",
    "        correct += (guess == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    \n",
    "    acc = 100*(correct/total) # Compute accuracy over epoch\n",
    "\n",
    "    basic_tr_accuracy.append(acc)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval() # put model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            # Compute Accuracy\n",
    "            guess = outputs.round().reshape(-1)\n",
    "            correct += (guess == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    basic_ts_accuracy.append(100*(correct/total))\n",
    "    \n",
    "    # Print details every print_mod epoch\n",
    "    print('Epoch: {0:2d}   Train Accuracy: {1:.3f}%   Test Accuracy: {2:.3f}%'.format(epoch+1, basic_tr_accuracy[epoch], basic_ts_accuracy[epoch]))\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "# Save\n",
    "PATH = 'saved_basic_model.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training auc:  0.9088695214912846\n"
     ]
    }
   ],
   "source": [
    "# compute the training accuracy\n",
    "with torch.no_grad():\n",
    "    predict = model(torch.Tensor(Xts)).detach().numpy().ravel()\n",
    "auc = roc_auc_score(yts,predict)\n",
    "print('training auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model: you must use the .pth format for pytorch models!\n",
    "model_savepath = 'model.pth'\n",
    "\n",
    "# To save a PyTorch model, we first pass an input through the model, \n",
    "# and then save the \"trace\". \n",
    "# For this purpose, we can use any input. \n",
    "# We will create a random input with the proper dimension.\n",
    "x = torch.randn(nin) # random input\n",
    "x = x[None,:] # add singleton batch index\n",
    "with torch.no_grad():\n",
    "    traced_cell = torch.jit.trace(model, (x))\n",
    "\n",
    "# Now we save the trace\n",
    "torch.jit.save(traced_cell, model_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training auc =  0.9170509493075445\n",
      "test label confidences saved in yts_hat_neural.csv\n"
     ]
    }
   ],
   "source": [
    "# generate kaggle submission file using the validation script\n",
    "!python {\"validation.py \" + model_savepath + \" --Xts_path \" + Xts_savepath + \" --Xtr_path \" + Xtr_savepath + \" --yts_hat_path \" + yts_hat_savepath } "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09bacf2e71db2ded6f823d81b11a48b2cca13137666d7b0f33e49c4d57c2ea92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
